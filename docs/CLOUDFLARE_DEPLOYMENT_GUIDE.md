# â˜ï¸ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Cloudflare - Cloudflare Deployment Guide

## **Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ - Saudi Store**
### **Ù†Ø´Ø± LLM Ø¹Ù„Ù‰ Cloudflare Ù…Ø¹ Tunnel Ù…Ø¨Ø§Ø´Ø±**

---

## **ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©**

Ø³Ù†Ù‚ÙˆÙ… Ø¨Ù€:
1. Ù†Ø´Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Cloudflare Pages
2. Ø¥Ù†Ø´Ø§Ø¡ Cloudflare Tunnel Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ
3. ØªØ´ØºÙŠÙ„ LLM Models Ø¹Ù„Ù‰ Cloudflare Workers AI
4. Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ AI Ù†Ø´Ø· Ø¯Ø§Ø¦Ù…Ø§Ù‹

---

## **ğŸ¯ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©**

```
Local Server (D:\LLM)
    â†“ Cloudflare Tunnel
Cloudflare Network
    â†“
Cloudflare Pages (Frontend)
Cloudflare Workers (API)
Cloudflare Workers AI (LLM)
Cloudflare Vectorize (Vector DB)
Cloudflare D1 (Database)
```

---

## **âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯**

### **1. ØªØ«Ø¨ÙŠØª Cloudflare CLI (Wrangler)**

```bash
npm install -g wrangler

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
wrangler login
```

---

### **2. Ø¥Ù†Ø´Ø§Ø¡ Cloudflare Tunnel**

```bash
# ØªØ«Ø¨ÙŠØª cloudflared
# Windows:
# Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù†: https://github.com/cloudflare/cloudflared/releases

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
cloudflared tunnel login

# Ø¥Ù†Ø´Ø§Ø¡ tunnel Ø¬Ø¯ÙŠØ¯
cloudflared tunnel create saudi-store-tunnel

# Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡:
# - Tunnel ID
# - Credentials file
```

---

### **3. ØªÙƒÙˆÙŠÙ† Tunnel**

**Ù…Ù„Ù: `cloudflared-config.yml`**

```yaml
tunnel: saudi-store-tunnel
credentials-file: /path/to/credentials.json

ingress:
  # Next.js App
  - hostname: saudi-store.yourdomain.com
    service: http://localhost:3050
  
  # WebSocket Server
  - hostname: ws.saudi-store.yourdomain.com
    service: http://localhost:3051
  
  # LLM Server
  - hostname: llm.saudi-store.yourdomain.com
    service: http://localhost:8000
  
  # PostgreSQL (optional, for admin)
  - hostname: db.saudi-store.yourdomain.com
    service: tcp://localhost:5432
  
  # Catch-all
  - service: http_status:404
```

---

### **4. ØªØ´ØºÙŠÙ„ Tunnel**

```bash
# ØªØ´ØºÙŠÙ„ Tunnel
cloudflared tunnel --config cloudflared-config.yml run saudi-store-tunnel

# Ø£Ùˆ ÙƒØ®Ø¯Ù…Ø© Windows
cloudflared service install
cloudflared service start
```

---

## **ğŸ¤– Cloudflare Workers AI**

### **Ù…Ù„Ù: `wrangler.toml`**

```toml
name = "saudi-store-ai"
main = "src/worker.ts"
compatibility_date = "2024-01-01"

# Cloudflare Workers AI
[ai]
binding = "AI"

# Cloudflare Vectorize
[[vectorize]]
binding = "VECTORIZE"
index_name = "saudi-store-embeddings"

# Cloudflare D1 Database
[[d1_databases]]
binding = "DB"
database_name = "saudi-store-db"
database_id = "your-database-id"

# KV for caching
[[kv_namespaces]]
binding = "CACHE"
id = "your-kv-id"

# Environment Variables
[vars]
ENVIRONMENT = "production"

# Secrets (use: wrangler secret put)
# OPENAI_API_KEY
# ANTHROPIC_API_KEY
# etc.
```

---

### **Ù…Ù„Ù: `src/worker.ts`**

```typescript
export interface Env {
  AI: any;
  VECTORIZE: Vectorize;
  DB: D1Database;
  CACHE: KVNamespace;
  
  // API Keys (secrets)
  OPENAI_API_KEY: string;
  ANTHROPIC_API_KEY: string;
  GOOGLE_AI_API_KEY: string;
}

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url);
    
    // CORS Headers
    const corsHeaders = {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    };
    
    if (request.method === 'OPTIONS') {
      return new Response(null, { headers: corsHeaders });
    }
    
    // Routes
    if (url.pathname === '/api/ai/generate') {
      return handleAIGeneration(request, env, corsHeaders);
    }
    
    if (url.pathname === '/api/ai/embed') {
      return handleEmbedding(request, env, corsHeaders);
    }
    
    if (url.pathname === '/api/ai/search') {
      return handleVectorSearch(request, env, corsHeaders);
    }
    
    return new Response('Not Found', { status: 404 });
  }
};

// ============================================
// AI GENERATION
// ============================================

async function handleAIGeneration(
  request: Request,
  env: Env,
  corsHeaders: Record<string, string>
): Promise<Response> {
  try {
    const { model, prompt, systemPrompt } = await request.json();
    
    let response;
    
    // Use Cloudflare Workers AI for supported models
    if (model === '@cf/meta/llama-3-8b-instruct') {
      response = await env.AI.run(model, {
        messages: [
          { role: 'system', content: systemPrompt || 'You are a helpful assistant' },
          { role: 'user', content: prompt }
        ]
      });
    }
    // Use external APIs for other models
    else if (model.startsWith('gpt-')) {
      response = await callOpenAI(prompt, systemPrompt, env.OPENAI_API_KEY);
    }
    else if (model.startsWith('claude-')) {
      response = await callAnthropic(prompt, systemPrompt, env.ANTHROPIC_API_KEY);
    }
    
    return new Response(JSON.stringify({
      success: true,
      response
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  } catch (error: any) {
    return new Response(JSON.stringify({
      error: error.message
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
}

// ============================================
// EMBEDDINGS
// ============================================

async function handleEmbedding(
  request: Request,
  env: Env,
  corsHeaders: Record<string, string>
): Promise<Response> {
  try {
    const { text } = await request.json();
    
    // Use Cloudflare Workers AI for embeddings
    const embeddings = await env.AI.run('@cf/baai/bge-base-en-v1.5', {
      text: text
    });
    
    return new Response(JSON.stringify({
      success: true,
      embeddings: embeddings.data[0]
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  } catch (error: any) {
    return new Response(JSON.stringify({
      error: error.message
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
}

// ============================================
// VECTOR SEARCH
// ============================================

async function handleVectorSearch(
  request: Request,
  env: Env,
  corsHeaders: Record<string, string>
): Promise<Response> {
  try {
    const { query, topK = 10 } = await request.json();
    
    // Generate embedding for query
    const embedding = await env.AI.run('@cf/baai/bge-base-en-v1.5', {
      text: query
    });
    
    // Search in Vectorize
    const matches = await env.VECTORIZE.query(embedding.data[0], {
      topK,
      returnMetadata: 'all'
    });
    
    return new Response(JSON.stringify({
      success: true,
      matches
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  } catch (error: any) {
    return new Response(JSON.stringify({
      error: error.message
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
}

// ============================================
// EXTERNAL API CALLS
// ============================================

async function callOpenAI(
  prompt: string,
  systemPrompt: string,
  apiKey: string
): Promise<any> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt }
      ]
    })
  });
  
  const data = await response.json();
  return data.choices[0].message.content;
}

async function callAnthropic(
  prompt: string,
  systemPrompt: string,
  apiKey: string
): Promise<any> {
  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'claude-3-opus-20240229',
      max_tokens: 1024,
      system: systemPrompt,
      messages: [
        { role: 'user', content: prompt }
      ]
    })
  });
  
  const data = await response.json();
  return data.content[0].text;
}
```

---

## **ğŸ“¦ Ø§Ù„Ù†Ø´Ø±**

### **1. Ù†Ø´Ø± Workers**

```bash
# Ù†Ø´Ø± Worker
wrangler deploy

# Ø¥Ø¶Ø§ÙØ© Secrets
wrangler secret put OPENAI_API_KEY
wrangler secret put ANTHROPIC_API_KEY
wrangler secret put GOOGLE_AI_API_KEY
```

### **2. Ù†Ø´Ø± Pages**

```bash
# Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
npm run build

# Ù†Ø´Ø± Ø¹Ù„Ù‰ Cloudflare Pages
wrangler pages deploy .next --project-name=saudi-store
```

### **3. Ø¥Ù†Ø´Ø§Ø¡ Vectorize Index**

```bash
wrangler vectorize create saudi-store-embeddings \
  --dimensions=768 \
  --metric=cosine
```

### **4. Ø¥Ù†Ø´Ø§Ø¡ D1 Database**

```bash
wrangler d1 create saudi-store-db
```

---

## **ğŸ”„ Keep AI Active**

### **Ù…Ù„Ù: `src/cron-worker.ts`**

```typescript
export default {
  async scheduled(event: ScheduledEvent, env: Env): Promise<void> {
    // Keep AI warm - run every 5 minutes
    try {
      // Test AI endpoint
      await env.AI.run('@cf/meta/llama-3-8b-instruct', {
        messages: [{ role: 'user', content: 'ping' }]
      });
      
      console.log('AI keepalive successful');
    } catch (error) {
      console.error('AI keepalive failed:', error);
    }
  }
};
```

**ÙÙŠ `wrangler.toml`:**

```toml
[triggers]
crons = ["*/5 * * * *"]  # ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚
```

---

## **ğŸŒ ØªØ­Ø¯ÙŠØ« Frontend**

### **Ù…Ù„Ù: `.env.production`**

```env
# Cloudflare Workers AI
NEXT_PUBLIC_AI_API_URL=https://saudi-store-ai.yourusername.workers.dev

# Cloudflare Tunnel URLs
NEXT_PUBLIC_APP_URL=https://saudi-store.yourdomain.com
NEXT_PUBLIC_WS_URL=https://ws.saudi-store.yourdomain.com
NEXT_PUBLIC_LLM_URL=https://llm.saudi-store.yourdomain.com
```

### **ØªØ­Ø¯ÙŠØ« Service:**

```typescript
// lib/services/cloudflare-ai.service.ts
export class CloudflareAIService {
  private static apiUrl = process.env.NEXT_PUBLIC_AI_API_URL;
  
  static async generate(prompt: string, model: string = '@cf/meta/llama-3-8b-instruct') {
    const response = await fetch(`${this.apiUrl}/api/ai/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt, model })
    });
    
    return await response.json();
  }
  
  static async embed(text: string) {
    const response = await fetch(`${this.apiUrl}/api/ai/embed`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    });
    
    return await response.json();
  }
  
  static async search(query: string, topK: number = 10) {
    const response = await fetch(`${this.apiUrl}/api/ai/search`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, topK })
    });
    
    return await response.json();
  }
}
```

---

## **ğŸ“Š Cloudflare Workers AI Models**

### **Ø§Ù„Ù…ØªØ§Ø­ Ø¹Ù„Ù‰ Cloudflare:**

```typescript
// Text Generation
'@cf/meta/llama-3-8b-instruct'
'@cf/meta/llama-2-7b-chat-int8'
'@cf/mistral/mistral-7b-instruct-v0.1'

// Embeddings
'@cf/baai/bge-base-en-v1.5'
'@cf/baai/bge-small-en-v1.5'
'@cf/baai/bge-large-en-v1.5'

// Translation
'@cf/meta/m2m100-1.2b'

// Image Generation
'@cf/stabilityai/stable-diffusion-xl-base-1.0'

// Speech Recognition
'@cf/openai/whisper'
```

---

## **ğŸ”§ Local Development Ù…Ø¹ Tunnel**

```bash
# Terminal 1: ØªØ´ØºÙŠÙ„ Next.js
npm run dev

# Terminal 2: ØªØ´ØºÙŠÙ„ WebSocket
npm run ws

# Terminal 3: ØªØ´ØºÙŠÙ„ Cloudflare Tunnel
cloudflared tunnel --config cloudflared-config.yml run

# Terminal 4: ØªØ´ØºÙŠÙ„ Wrangler (local dev)
wrangler dev
```

---

## **ğŸ“ˆ Monitoring**

### **Cloudflare Dashboard:**
- Workers Analytics
- Pages Analytics
- Tunnel Status
- AI Usage
- Vectorize Queries

### **Logs:**

```bash
# Worker logs
wrangler tail

# Tunnel logs
cloudflared tunnel info saudi-store-tunnel
```

---

## **ğŸ’° Ø§Ù„ØªÙƒÙ„ÙØ©**

### **Cloudflare Free Tier:**
- âœ… Workers: 100,000 requests/day
- âœ… Pages: Unlimited requests
- âœ… Tunnel: Ù…Ø¬Ø§Ù†ÙŠ
- âœ… Workers AI: 10,000 neurons/day
- âœ… Vectorize: 5M queries/month
- âœ… D1: 5GB storage

### **Paid Plans:**
- Workers Paid: $5/month + usage
- Workers AI: Pay as you go
- Enterprise: Custom pricing

---

## **âœ… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ù‚Ù‚**

- [ ] ØªØ«Ø¨ÙŠØª wrangler
- [ ] ØªØ«Ø¨ÙŠØª cloudflared
- [ ] Ø¥Ù†Ø´Ø§Ø¡ Cloudflare Tunnel
- [ ] ØªÙƒÙˆÙŠÙ† cloudflared-config.yml
- [ ] Ø¥Ù†Ø´Ø§Ø¡ wrangler.toml
- [ ] Ø¥Ù†Ø´Ø§Ø¡ Worker
- [ ] Ø¥Ù†Ø´Ø§Ø¡ Vectorize Index
- [ ] Ø¥Ù†Ø´Ø§Ø¡ D1 Database
- [ ] Ø¥Ø¶Ø§ÙØ© Secrets
- [ ] Ù†Ø´Ø± Worker
- [ ] Ù†Ø´Ø± Pages
- [ ] ØªØ´ØºÙŠÙ„ Tunnel
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„

---

## **ğŸš€ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø³Ø±ÙŠØ¹Ø©**

```bash
# Setup
npm install -g wrangler
wrangler login
cloudflared tunnel login

# Create Resources
cloudflared tunnel create saudi-store-tunnel
wrangler vectorize create saudi-store-embeddings --dimensions=768
wrangler d1 create saudi-store-db

# Deploy
wrangler deploy
wrangler pages deploy .next --project-name=saudi-store

# Run
cloudflared tunnel run saudi-store-tunnel
wrangler dev
npm run dev
```

---

**ğŸ‰ Cloudflare Deployment Ø¬Ø§Ù‡Ø²!**

**Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
âœ… Cloudflare Tunnel Ù„Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±  
âœ… Workers AI (16+ models)  
âœ… Vectorize Ù„Ù„Ø¨Ø­Ø«  
âœ… D1 Database  
âœ… Pages Ù„Ù„Ù€ Frontend  
âœ… Keep AI Active (Cron)  
âœ… Free Tier Ù…ØªØ§Ø­  
âœ… Global CDN  
âœ… Auto-scaling  

**ğŸš€ Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ - Saudi Store**
