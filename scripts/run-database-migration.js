#!/usr/bin/env node

/**
 * Database Migration Runner
 * Saudi Business Gate Platform - Missing Tables Migration
 */

import { Pool } from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

// Get current directory for ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runMigration() {
    console.log('üöÄ Starting database migration for missing tables...');
    
    // Database connection
    const pool = new Pool({
        connectionString: process.env.DATABASE_URL,
        ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
    });

    try {
        // Test connection
        console.log('üì° Testing database connection...');
        const client = await pool.connect();
        console.log('‚úÖ Database connection successful');
        client.release();

        // Read migration file
        const migrationPath = path.join(__dirname, '..', 'database', 'migrations', '001_create_missing_tables.sql');
        console.log(`üìÑ Reading migration file: ${migrationPath}`);
        
        if (!fs.existsSync(migrationPath)) {
            throw new Error(`Migration file not found: ${migrationPath}`);
        }

        const migrationSQL = fs.readFileSync(migrationPath, 'utf8');
        console.log('üìñ Migration file loaded successfully');

        // Execute migration
        console.log('‚ö° Executing migration...');
        const result = await pool.query(migrationSQL);
        console.log('‚úÖ Migration executed successfully');

        // Verify tables were created
        console.log('üîç Verifying created tables...');
        const tableCheck = await pool.query(`
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name IN ('ai_agents', 'themes', 'tenant_webhook_configs', 'notifications', 'workflow_templates', 'workflow_executions')
            ORDER BY table_name
        `);

        console.log('üìä Created tables:');
        tableCheck.rows.forEach(row => {
            console.log(`   ‚úÖ ${row.table_name}`);
        });

        // Check record counts
        console.log('üìà Initial data verification:');
        const tables = ['ai_agents', 'themes', 'workflow_templates'];
        
        for (const table of tables) {
            try {
                const countResult = await pool.query(`SELECT COUNT(*) as count FROM ${table}`);
                console.log(`   üìã ${table}: ${countResult.rows[0].count} records`);
            } catch (error) {
                console.log(`   ‚ùå ${table}: Error checking records - ${error.message}`);
            }
        }

        console.log('\nüéâ Database migration completed successfully!');
        console.log('üìã Summary:');
        console.log('   ‚úÖ ai_agents - AI agent management system');
        console.log('   ‚úÖ themes - Theme customization system');
        console.log('   ‚úÖ tenant_webhook_configs - Webhook configurations');
        console.log('   ‚úÖ notifications - Notification system');
        console.log('   ‚úÖ workflow_templates - Workflow management');
        console.log('   ‚úÖ workflow_executions - Workflow execution tracking');
        console.log('\nüöÄ Your application is now ready for production database operations!');

    } catch (error) {
        console.error('‚ùå Migration failed:', error.message);
        console.error('Stack trace:', error.stack);
        process.exit(1);
    } finally {
        await pool.end();
        console.log('üîå Database connection closed');
    }
}

// Handle command line execution
if (import.meta.url === `file://${process.argv[1]}`) {
    runMigration().catch(error => {
        console.error('‚ùå Fatal error:', error);
        process.exit(1);
    });
}

export { runMigration };
